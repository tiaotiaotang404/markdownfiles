## 处理器系统_框架 摘录

#### [1] K. Patsidis, D. Konstantinou, C. Nicopoulos, G. Dimitrakopoulos, A low-cost synthesizable RISC-V dual-issue processor core leveraging the compressed Instruction Set Extension, Microprocessors and Microsystems, 61 (2018) 1-10.

##### 【双数据路径，同时执行两条压缩指令】

The concept introduced in this work of simultaneously executing two compressed RISC-V instructions within the microprocessor’s datapath is similar in vein to the VLIW mode of the non-RISC-V processor presented in [29]. The 32-bit VLIW RISC core proposed in said paper has a double datapath that can execute a pair of 16-bit instructions fetched concurrently as a 32-bit VLIW word. However, being a VLIW design, the processor in [29] relies entirely on the compiler to resolve dependencies, while the pair of 16-bit instructions can never be separated during the execution flow, which means that any stall affects both instructions at the same time. On the contrary, our approach performs scheduling of compressed instructions dynamically in hardware, and the two instructions are fully decoupled during execution and are even allowed to complete execution out-of-order.

The processor is implemented in a 6-stage pipelined organization that includes the following stages: (a) Instruction Fetch (IF), (b) Instruction Decode (ID), (c) Register Renaming (RR), (d) Instruction Issue (IS), (e) Execution (EX), and (f) Write-Back (WB). A high-level overview of the proposed processor’s micro-architecture is depicted in Fig. 1. Instructions are fetched and issued for execution in program order. The write-back/retirement stage is also in-order. However, the execution can be completed out-of-order. The duration in cycles of the EX stage is variable and it depends on the operation being executed. Table 2 summarizes the EX latencies of the various instruction types. For some instructions, the EX stage either requires several cycles to complete, or it is further pipelined in several sub-stages. Consequently, the overall pipeline depth is not 6 stages for all instructions; some instructions will experience a longer pipeline depth, due to a higher latency in their EX stage. Simple instructions, such as branches, logical operations, and additions/subtractions, take only a single cycle to complete their EX stage, i.e., they experience the nominal 6-stage pipeline. Division needs 16 cycles to complete its EX stage, during which the pipeline is busy, while multiplication is fully pipelined, with an EX latency of 4 cycles. Finally, the execution latency of memory operations is not constant, because it depends on the state of the data cache. The EX latency of memory operations can vary from a single cycle, up to several cycles, if a data cache miss occurs.

3.1. Front-end The frond-end of the microprocessor is responsible for the fetching
and decoding of the instructions. The instructions are subsequently fed to the back-end of the processor core for execution and retirement. The instruction-fetch sub-system of the front-end comprises the instruction cache and a dynamic predictor module. For optimal performance, the fetch stage should – ideally – provide a continuous stream of useful instructions, i.e., instructions on the correct execution path. To enable such seamless and continuous flow of instructions, the predictor module predicts the path that each branch will take, while the instruction cache reduces the penalty of the memory accesses. The synergistic symbiosis of these two elemental sub-systems is critical in achieving high performance. In each clock cycle, the Program Counter (PC) address is supplied in parallel to both the instruction cache and the dynamic predictor, from which the fetched instruction and the next PC address are procured, respectively. The dynamic predictor itself utilizes three sub-modules, as illustrated in Fig. 1. The Branch Target Buffer (BTB) records the target PC address of each branch instruction, in order to expedite the determination of branch-taken addresses. Each of the BTB’s entries holds a tag and a full 32-bit target address. Its indexing is performed by supplying the current PC address. If a tag match is identified, the predicted target address is the one stored in the matched entry. The correlated branch-direction predictor maintains a history of the
outcomes of previous occurrences of each branch. Based on this history, the predictor can guess the direction, i.e., taken/non-taken, of the current branch. The predictor is indexed using the current PC address. Each entry contains several potentially saturated counters. One of these counters is picked using the global branch history – recorded in a separate register – XORed with some bits of the PC address, thereby adopting a Gshare indexing scheme. The state of this counter will provide the final prediction. Recall that only a taken/non-taken prediction is generated by this sub-module. The actual target address of the branch is retrieved from the aforementioned BTB sub-module. Finally, the Return Address Stack (RAS) stores the return addresses of the decoded function calls. When the function’s return instruction is encountered, the entry popped from the RAS is used as the next PC address. The RAS is a complementary structure to the other two submodules of the predictor, and its aim is to improve the predictor’s accuracy when dealing with branch instructions used for function calls/ returns. The instruction cache is a typical blocking cache structure. In the case of a hit, the access is completed within the same cycle. However, if a miss occurs, the cache “blocks” until the requested data is provided by the lower level of the memory hierarchy. The replacement policy uses a pseudo-LRU scheme to choose which block will be evicted. The fetch width is constant at 32 bits per cycle. Fetches at the edge of cache blocks are converted into two-cycle operations, in which the data is retrieved in packets and then re-assembled. The instruction alignment is done at 16-bit boundaries. This implies that, within the 32 fetched bits, one may find one full 32-bit instruction, or two compressed 16-bit instructions, or even invalid parts of instructions, if misalignment occurs. Any misalignment is detected and signalled by the decoder, so that the fetch sub-system can redirect and re-align to the correct address. Redirection also occurs if a branch resolution indicates a misprediction. The Instruction Decode (ID) stage is responsible for decoding the fetched 32-bit instruction chunk. It contains one decoder for full-length 32-bit instructions, and two decoders for compressed 16-bit
4
instructions. In RISC-V ISA the fields are always encoded in the same place inside the instruction body, which makes the decoding fairly straight-forward. As previously mentioned, the ID stage is also responsible for detecting misalignment and invalid instructions, which generate appropriate signalling for the IF stage to realign and resume. It should be noted that adding support for compressed instructions
is not a straight-forward task, as also described in [30]. Not all 16-bit instructions map fully to the corresponding 32-bit ones. This means that the pipeline must be aware of the nature of the instructions, i.e., whether they were originally compressed. The same applies to the program flow controllers and predictors, which should also track whether any given instruction was originally compressed or not. We tackle this problem by efficiently allocating internal micro-op codes to the instructions, and by tracking the program flow in the ID stage, where all necessary information is readily available. This removes the need for any extra book-keeping in the pipeline.
3.2. Register Renaming and dispatch to execution Upon completion of the ID stage, the decoded instructions are fed
into the Register Renaming (RR) stage. The inclusion of such a subsystem was deemed necessary after detailed profiling analysis of several benchmark applications, which revealed a key attribute pertaining to how the available registers are utilized by the RISC-V compiler. The details of our evaluation framework and the profiling analysis of the benchmarks are presented in Section 4. It turns out that, when using instruction compression, the RISC-V ISA specification dictates the use of predominantly 8 specific registers for some classes of compressed instructions, namely registers x8–x15. These 8 registers are used, on average, 72% of the time across all examined benchmarks, and, naturally, they give rise to a huge amount of name hazards/dependencies, write-after-write and write-after-read. To mitigate this artificial bottleneck and reap all the potential
benefits of using compressed instructions, the proposed processor design employs selective register renaming targeting only registers x8–x15. Through register renaming, the 8 heavily used architectural registers are spread out to 16 physical registers. An overview of the proposed selective register renaming scheme is shown in Fig. 2. Selective – rather than full – renaming allows for significant area savings, since only 40 physical registers are needed in total, 32 existing + 8 extra for renaming, instead of the 64 that would be required if all 32 architectural registers were to be renamed. Furthermore, due to the limited scope of the renaming, all the structures required for renaming are significantly smaller. Up to two instructions can be renamed per cycle, to enable dualissue functionality later on, as shown in Fig. 2. The renaming system utilizes a Register Alias Table (RAT) that keeps track of the mapping of the 8 “hot” architectural registers to the 16 physical ones. Since the RAT is corrupted on mis-predicted branches, the RAT uses a checkpoint-based repair mechanism. Each new renamed branch triggers a new checkpoint capture. If the branch ends up being mis-predicted, the RAT can be repaired within a single cycle, by restoring the corresponding checkpoint. Up to four checkpoints are supported, and, therefore, up to four branches can be in-flight simultaneously. A freelist structure is also used, which is a simple queue holding the identifiers of the free physical registers that can be allocated to the incoming instructions. The renamed instructions then pass through the Issue Stage (IS),
before being dispatched for execution. The IS stage is built around a simple score-boarding mechanism, which keeps track of the status of each physical register. The score-board has a total of 40 entries, one for each physical register. It keeps track of each register’s usage, as well as the location of the latest data. If some pertinent conditions are satisfied, up to two instructions may be dispatched in-order for execution. The conditions that must be met before dispatching are: (a) the source data must be available, (b) the functional units must be ready to accommodate new instructions, and (c) no conflicts – dependent data, or use of the same functional unit – must exist between the instructions. The supported dual-issue functionality allows for the simultaneous issuing of two compressed 16-bit instructions without the need to double the fetch width. Thus, in addition to exploiting compressed instructions to reduce the code size, the proposed processor design also reaps performance – throughput – benefits through the dual issuing of two consecutive compressed instructions to execution. Instructions that are dispatched to execution obtain their source
operands from the Register File, as indicated in Fig. 1. In the proposed implementation, the register file design capitalizes on the skewed use of the registers when instruction compression is employed. Recall that the registers used most of the time are 16 specific registers, i.e., registers x8–x15 and the 8 physical registers used in the selective register renaming scheme. The remaining 24 architectural registers are used markedly less often. This operational characteristic has motivated us to design a partitioned register file, which is split in two segments: one housing the 16 frequently used registers, i.e., the selectively renamed registers, and the other housing the 24 registers that are not accessed so frequently, i.e., not renamed. The architecture of the employed partitioned register file is abstractly illustrated in Fig. 3. Essentially, the register file is partitioned into a “hot” segment that is primarily used during execution, and a “cold” segment that is used more sporadically.

![image-20230722110147269](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230722110147269.png)

3.3. Back-end The back-end of the processor core consists of the Execution (EX)
and the Write-Back (WB) stages. There are four functional units in the EX stage, each tasked with different operations. The first unit is the integer ALU. All its operations are pipelined and, therefore, it can accept a new instruction every cycle. The only operation that will cause the unit to block is division, which is not pipelined. The second unit is the branch-resolve unit, responsible for the resolution of all branch instructions. The execution of this particular unit always finishes within one cycle. The third unit is the load/store unit that has a direct connection to the data cache. Since RISC-V is a load-store ISA, the data cache can also provide lock-free operation. This means that upon misses, it can continue to serve new instructions while waiting for the data to arrive from the next level of the memory hierarchy. This was a deliberate design choice, so that the performance of the processor could be somewhat decoupled from the performance of the memory system. To achieve non-blocking operation, we employ buffers (load/store/ wait) that store relevant information of the instructions that missed, until they can be served. The fourth functional unit is the floating-point ALU, which, in the current implementation, is missing. The whole pipeline organization is fully ready to support floating-point instructions; the only remaining module to be implemented in the next incarnation of the processor is the floating-point unit. The WB stage is facilitated through the use of a Re-Order Buffer
(ROB). This pipeline stage uses the well-established “data-in-ROB” scheme, whereby all execution results are temporarily stored within the ROB, until the instructions can commit/retire. The ROB maintains the correct program order during the retirement of the instructions, and allows for speculative execution beyond branches. In each clock cycle, only the oldest – in terms of program order – instruction can commit and modify the architectural state of the processor. Retirement includes writing the results to the physical register file, or saving the data in the data cache, in the case of store instructions. Because the retirement rate is limited to one instruction per cycle in the current implementation, the effective maximum throughput of the pipeline is also set to one instruction per cycle.

![image-20230722110202475](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230722110202475.png)

#### [2] N.N. Sharma, R. Jain, M.M. Pokkuluri, S.B. Patkar, R. Leupers, R.S. Nikhil, F. Merchant, CLARINET: A quire-enabled RISC-V-based framework for posit arithmetic empiricism, Journal of Systems Architecture, 135 (2023).

##### 【posit 算法】



#### [3] D.A.N. Gookyi, R. Kwangki, Selecting a Synthesizable RISC-V Processor Core for Low-cost Hardware Devices, Journal of Information Processing Systems, 15 (2019) 1406-1421.



#### [4] Y.H. Cheng, L.B. Huang, Y.J. Cui, S. Ma, Y.W. Wang, B.C. Sui, RV16: An Ultra-Low-Cost Embedded RISC-V Processor Core, Journal of Computer Science and Technology, 37 (2022) 1307-1319.

##### 【16位处理器的结构设计与实现】

3 RV16 Microarchitecture 

RV16 can be configured to support RISC-V “E”,
“I”, “M”, and “C” standard extension. The difference between RV32E and RV32I is that RV32E contains only 16 general-purpose registers, while RV32I contains 32. “M” extension requires to additionally support hardware multiplication and division based on RV32E or RV32I. And the length of instruction in the “C” standard extension is 16-bit, which can reduce the storage space required by the program. The microarchitecture of RV16 is shown in Fig.1,
in which two pipeline stages are named IFA (Instruction Fetch and Align) and IDE (Instruction Decode and Execution). The rest of this section will introduce the pipeline structure of RV16 in detail.

![image-20230723091252246](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723091252246.png)

3.1 Instruction Fetch and Align The IFA stage generates an instruction address and
sends it to instruction memory every cycle. Considering the length of instruction in the RV32I base instruction set, RV16 still has a 32-bit instruction path to fetch 32bit instruction data in each cycle. It makes possible for RV16 to complete a 32-bit instruction that processes 32-bit data in one cycle. However, the support for the “C” extension may make the length of the instruction processed by RV16 be 16-bit or 32-bit. An instruction from the instruction memory needs to be aligned firstly by an instruction aligner to identify the compressed instruction. Before sending the instruction to the decoder, the compressed instruction will be translated into an uncompressed instruction in the compressed instruction decode unit (named C2I in Fig.1). In order to minimize the hardware resource consumption, in RV16, only a 16-bit register is used to store 16-bit instruction data that may not be used in one cycle. An instruction is generated by combining the data in the register and the data from the instruction memory according to whether the data in the register is valid or not.
3.2 Instruction Decode and Execution A RISC-V instruction always processes 32-bit data
by default. As a result, the decode and execution units in the IDE stage of RV16 are different from traditional RISC-V processors because of the 16-bit data path that can only process a 16-bit operand per cycle. RV16 solves this problem by increasing the execution cycle of an instruction to reuse the 16-bit data path and units. Understandably, for most instructions in RISC-V, RV16 will take two execution cycles to complete the response operation: one cycle processes the lower 16-bit in 32-bit data, and the other cycle processes the upper 16-bit.
3.2.1 Decoder In two execution cycles of one instruction, the RV16
decoder is required to generate different control signals at different execution cycles to select the correct data and operation. As shown in Fig.2, when the decoder decodes an instruction, it depends not only on the input instruction but also on the execution status of the instruction (it is represented by a one-bit signal, named ex status in Fig.2, which is reset to 0 in the first execution cycle of one instruction). In practice, the execution status is used to indicate whether the upper 16 bits or lower 16 bits of the 32-bit data should be processed in the current execution cycle. Therefore, the signals related to the operand will be affected by the execution status (such as reg addr and imm in Fig.2).
3.2.2 Register File There are two ways to implement the register file
based on the 16-bit internal data path. The first way keeps each register 32 bits and selects the lower or upper 16 bits of a register through a control signal. The second way is to divide each 32-bit register into two 16bit registers and index them by address. Our experiments prove that the latter consumes fewer hardware resources because its control logic is simpler. As a result, 16 32-bit registers in RV32E and 32 32-bit registers in RV32I are implemented by a register file containing 32 and 64 16-bit registers, respectively. The read and write logic of the register file in RV16
is shown in Fig.3. Different from traditional RISC-V processors, the register address of RV16 consists of the register number in the instruction and an additional least significant bit. The least significant bit of the register address is determined by the type of instructions and its execution status. In most cases, when an instruction enters the IDE stage from the IFA stage, the lower 16-bit data is pro-cessed in the first execution cycle, and the upper 16-bit is processed in the next cycle. For example, to process an ADD instruction, RV16 reads and writes the lower 16-bit register in the first execution cycle, which sets the least significant bit of register file address to 0. In the second execution cycle, it will operand the upper register, and the least significant bit will be set to 1. Obviously, in these cases, the least significant bit is equal to ex status in Fig.3. However, there are some exceptions. Firstly, for
shift right instructions, there is no way to handle the lower 16-bit data without the upper 16-bit, because the bits shifted out from the upper 16-bit data will appear in the lower 16-bit result. RV16 cannot read the upper 16-bit data while reading the lower data without adding the register file read port in one cycle. As a consequence, for these instructions, RV16 first processes the upper 16-bit data and keeps it in a special register for
reuse in the next cycle. At this point, the least significant bit is equal to NOT ex status in Fig.3. Secondly, for load and store instructions, the base address register is the lower 16-bit register and cannot change during the memory access because of the 16-bit address space; thus the least significant bit is always equal to 0.
3.2.3 Arithmetic Logic Unit The arithmetic logic unit (ALU) in RV16 includes
three parts: a shifter, an adder, and a logic unit, as shown in Fig.4(a). The compare unit after the adder generates signals to indicate the magnitude relationship between the two operands according to the result of the adder, which is used to achieve the compare and branch instructions. The logic unit of RV16 is a traditional 16bit logic unit because bits of the logical result do not affect each other, while the shifter and the adder are different from the traditional RISC-V processor.

![image-20230723091420069](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723091420069.png)

As mentioned earlier, the correct 32-bit result cannot be obtained if only 16-bit data is used per cycle for a shift operation. RV16 processes the upper 16-bit data first for a shift right operation and the lower first for a shift left operation. The advantage is that the 16-bit data processed first does not depend on other 16-bit data for a 32-bit operand. The detailed logic of the RV16 shifter is shown in
Fig.4(b), which is mainly composed of a 32-bit shifter. The operand of the 32-bit shifter is spliced by two 16bit operands (op1 and op3 in Fig.4(b)). And op3 is set to 1 or 0 by bit according to the shift mode in the first execution cycle and is equal to the previous op1 in the second cycle. For example, an SRA (shift right arithmetic) instruction sets all bits of op3 to the sign bit of the shifted data and lets op1 equal the upper 16 bits of the shifted data in the first execution cycle. In the second execution cycle, op3 is equal to the first cycle op1, and op1 is equal to the lower 16 bits of the shifted data. The SRA instruction always generates a 32-bit shifter operand according to op3 in the upper 16 bits and op1 in the lower. Lastly, it selects the lower 16 bits of the 32-bit shift result to write to the destination register as the result of this cycle. For the adder, it is obvious that the lower carry bit
needs to be considered in the upper 16-bit operation. Therefore, unlike the traditional RISC-V processor, the adder in RV16 needs to process the carry signal. Understandably, the carry signal is set to 0 in the first execution cycle and is generated by the first cycle in the second execution cycle.
3.2.4 Multiplier and Divider for RV32M Multiplier and divider exist only in RV16 that supports RISC-V “M” standard extension. The implementation of the divider is similar to that of the traditional RISC-V processor but the operands require two cycles to pass in. RV16 provides two implementations of multiplier for configurability: fast multiplier (F) and slow multiplier (S). In the fast multiplier, the 32-bit multiplication operation is achieved by a 16-bit single-cycle multiplier. When the lower 32 bits of the multiplication result are needed (MUL instruction), three 16-bit multiplication operations are required. When the upper 32 bits are needed (MULH instruction), four operations are required. And the slow multiplier is implemented by accumulating operands in multiple cycles.

3.3 Optimization 

Generally, it will take two cycles to process a 32bit operation (except for multiplication and division) by the 16-bit data path, which has a significant impact on performance. As a result, RV16 has proposed some optimization methods for certain RV32I instructions to improve performance.

First of all, the branch instruction judges the magnitude relationship between the two operands and determines if the branch is taken or not based on the result. In RV16, whether a branch instruction handles the lower 16-bit data is determined by the result of the upper operation. Only when the upper 16 bits of two operands are equal, the lower bits will be processed. If they are not equal, RV16 can directly get the result of the relationship between them. Additionally, LBU (load byte unsigned) and LHU
(load half-word unsigned) instructions can hide onecycle delay required to access memory by writing the upper 16-bit destination register first. As shown in Fig. 5, the first execution cycle of a load instruction generates and sends the address to data memory, and writes 0 to the upper destination register. In the second execution cycle, the first 16-bit load data is already valid and can be written into the lower destination register. At this point, LBU and LHU have been completed. If an LB (load byte) or LH (load half-word) instruction is being executed, whether the third execution cycle is needed depends on the sign bit of the load data. And for an LW (load word) instruction, RV16 will load the higher data from memory in the second execution cycle, and write the load data to the upper destination register in the third cycle.

Similarly, an SLT (set less than) instruction only
needs to write 0 or 1 to the destination register, and thus its upper 16-bit destination register is always 0. Therefore, in the first execution cycle, RV16 writes 0 to the upper destination register because the result of the comparison between the two operands has not come out. Then, RV16 only requires to write 0 or 1 to the lower destination register according to the comparison result in the second execution cycle.

![image-20230723091636889](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723091636889.png)

3.4 Theoretical Execution Cycles Table 1 counts the number of theoretical execution
cycles required by various RISC-V instructions in RV16. Because RV16 only supports the 16-bit address space, the Jump instruction calculates the target address and saves the return address in the first cycle, and jumps to the correct address to fetch the instruction in another cycle. The Branch instruction requires one or two cycles when the branch is not taken, and just like Jump, an extra cycle is required to jump to the target when the branch is taken. All ALU instructions require two cycles to process higher and lower 16 bits of the 32-bit operand separately. LBU/LHU and LW instructions can be completed in two cycles and three cycles respectively; LB and LH require two or three cycles depending on the sign bit. The SB (store byte) and SH (store halfword) instructions can be completed in one cycle, while SW (store word) requires two cycles. MUL and MULH require three cycles and five cycles in the fast multiplier, respectively, while they both require 35 cycles in the slow multiplier. Lastly, the division operation requires three cycles when the divisor is equal to zero, while 38 cycles are required in the other cases.

![image-20230723091703337](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723091703337.png)

#### [5] T.T. Hoang, C. Duran, K.D. Nguyen, T.K. Dang, Q.N.Q. Nhu, P.H. Than, X.T. Tran, D.H. Le, A. Tsukamoto, K. Suzaki, C.K. Pham, Low-power high-performance 32-bit RISC-V microcontroller on 65-nm silicon-on-thin-BOX (SOTB), Ieice Electronics Express, 17 (2020).

##### 【主要是CMOS管的结构设计，与处理器架构设计没啥太大关系】

Architecture
Fig. 1 shows the proposed architecture of the microcontroller. The core processor is the VexRiscv CPU generated with full options [26], including cache trashing, cache exceptions, single cycle barrel shifter, debug module via JTAG, dynamic branching, and Memory Management Unit (MMU). Comparing to the original design from the SpinalHDL [26], for better fitting in the chip, the caches sizes were increased a little bit to 4.5KB for each of the data and instruction caches.

The SPI controller was added for the usage of the SD-card. The GPIO has 16 LEDs and 16 switches. The 64KB size of the on-chip memory was chosen due to the size limitation of the intended fabricated chip. The 8KB of boot ROM contains 7KB of hard-code in combinational logics and 1KB of a stack in SRAM. The 1KB of SRAM stack can be used later after boot. The 7KB hard-code boot ROM inits the Control/Status Registers (CSRs) in the CPU, prints the initial text to the UART, starts the SD-card, loads the program from the SD-card to the on-chip memory, and jumps to the on-chip memory and executes there. With this boot flow, the microcontroller can self-boot to run any desired software in the SD-card for an embedded application. The source codes and guide for replicating this proposed microcontroller are published in the given repository [29].

![image-20230723092209698](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723092209698.png)

#### [6] S.S. Philip, R. Passerone, K.S. Yildirim, D. Brunelli, Intermittent Computing Emulation of Ultralow-Power Processors: Evaluation of Backup Strategies for RISC-V, Ieee Transactions on Computer-Aided Design of Integrated Circuits and Systems, 42 (2023) 82-94.

##### 【能量采集电路、超低功耗、间歇性算法】



#### [7] S. Bora, R. Paily, A High-Performance Core Micro-Architecture Based on RISC-V ISA for Low Power Applications, Ieee Transactions on Circuits and Systems Ii-Express Briefs, 68 (2021) 2132-2136.

II. MICRO-ARCHITECTURE 

In this section, we will detail micro-architectural optimizations for increasing the efficiency of the processor core. The starting point of this brief is RISC-V ISA. The core supports the base integer instruction set of RISC-V ISA with integer multiplication and division extension. This micro-architecture can be used as the base of an advanced core for supporting extensions and features. The main focus of this brief is on the optimizing the core power and performance. The efficient design of primary components of any system leads to an overall improvement of that system. So, in the proposed microarchitecture, basic components of the core like multiplier, divider, DBP, etc. are optimized to get the best possible result. The critical path of the core is also optimized to achieve a maximum frequency close to 200 MHz. Pipeline stages are organized in such a way that minimum data, control, and structural hazards can occur. These points are discussed in more detail in the following part of this section. The number of pipeline stages is one of the critical aspects
of any processor design. A higher number of pipeline stages allows a designer to achieve higher operating frequency, which leads to an increase in overall throughput. However, it also increases data and control hazards and reduces the IPC (Instructions per Cycle). For achieving high-performance, processors are also optimized using branch predictions, prefetch buffers, and speculation. However, these optimizations increase power consumption and are usually not suitable for low power applications. For example, ARM Cortex-M4 is a three-stage pipelined micro-architecture with a single writeback port in the register bank. The absence of the second write-back port and fourth pipeline stage brings stall while executing load operations. A three-stage pipeline is good for achieving high IPC, but the frequency of such a pipeline is limited because of multiple operations in a single stage. The proposed micro-architecture is designed in four pipeline stages in order to achieve a balance between IPC and frequency. The pipeline stages of the proposed core are Instruction Fetch (IF), Instruction Decode (ID), Instruction Execute (IE) and Register Write (RW), as shown in Figure 1. Most of the instructions can be completed within these four stages. But, there are few instructions for which this pipeline is modified to get optimum performance. The unconditional jump instruction JAL is completed after the first stage as it does not involve any register read/write operation. Load instructions require another stage before RW stage because the execution of these instructions involve memory access delays. Load instructions require another stage (Memory Read) before RW stage because the execution of these instructions involve memory access delays. The proposed core supports base integer instruction set
RV32I with multiplier extension M. Multiplication and division of 32-bit numbers is an expensive process in terms of critical path delay. So, these operations are executed in multiple clock cycles to reduce the critical path delay. The core has a 2-bit branch predictor with a history table. A 2-bit prediction counter is the right balance between hardware complexity and accuracy. More than two bits counter results in a higher complexity with only a little improvement of accuracy. Whereas a 1-bit counter is lesser complex, but the prediction accuracy is poorer.

![image-20230723102214983](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723102214983.png)

A. Instruction Execute 

![image-20230723102236539](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723102236539.png)

Figure 2 shows the block level representation of the IE
stage. In IE stage, register values are first checked. If they are ready to read, execution continues; otherwise, values are fetched from IE/RW stage, depending on previous instructions. These register values are then fed into different Functional Units (FU) of IE stage for execution. The IE stage has five FUs. These FUs with their operations and clock cycles are mentioned below: 1) ALU - add, sub, and, or, xor (1 clock) 2) Comparator - signed/unsigned comparison (1 clock) 3) Shifter - logical/arithmetic shift (1 clock) 4) Multiplier - signed/unsigned multiplication (2 clocks) 5) Divider - signed/unsigned division (8 clocks). IE stage also generates the memory read/write signals and
branch signals. Memory read/write address is obtained from the ALU unit, and memory read/write data is obtained from the second source register, i.e., rs2. Memory read/write enable signal comes from the instruction ID stage. These three signals are then combined to control the memory read/write operations. Branch consists of two signals; branch enable and branch address. Branch address is assigned from ALU output, and comparator output triggers the branch enable signal depending on the type of instruction. Multiplier and Divider circuits are vital parts of any core micro-architecture and their hardware complexity is very high compared to other functional units of IE stage. So, implementing a correct hardware circuit for multiplication and division has a vital role in the overall area, power, and performance of a core. 1) Multiplier: There is a lot of binary multiplication methods [14]–[16] available in literature namely Baugh and Wooley [17], Booth [18], Vedic [19], Dadda [20] etc. The hardware circuits for some popular multiplication methods are implemented using verilog HDL and the most suitable circuit is selected based on our requirements. These designs are then synthesized using Synopsys DC at UMC 40nm technology node and results are shown in Table I. Among all the implementations Baugh Wooley signed multiplier is found to be the most suitable one for our micro-architecture.

![image-20230723102431163](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723102431163.png)

From Table I, it can be seen that the delay of Baugh Wooley
signed multiplier circuit is 5.97 ns. If this circuit is used directly in the IE stage, the critical path of the overall system increases. Therefore, the hardware circuit of multiplier is modified into two stages. In the first stage, partial products are calculated using (1). Then, they are divided into six parts as shown in Figure 3 and are added. The adder results are then buffered to the next stage. In the second stage, the six buffered results are added again to get the final result. The critical path of the first stage consists of 1 HA (Half Adder) and 29 FAs (Full Adders). Whereas for the second stage, it consists of 1 HA and 47 FAs. The whole partial product segmentation is done in such a way that the delay of the first stage remains lesser than the second stage. This is because the input data of multiplier may come from register bank or from other stages of the pipeline. So, a multiplexer delay is expected at the inputs of multiplier circuit.

![image-20230723102504398](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723102504398.png)

Similar to the implementation of multiplication, the hardware circuits for available division algorithms [21] are implemented using Verilog HDL and synthesized at UMC 40 nm technology node. Table II shows the area, power, delay, latency and throughput of these circuits. The throughput is measured in terms of the number of inputs the circuit can execute per clock cycle. From Table II, it can be seen that as we move to higher radix algorithms, latency of the circuit decreases and as a result, throughput increases. If the results of radix-16 and radix-32 are compared, it can be seen that there is not much improvement in latency and throughput. But, there is a significant increment in power and area. So, radix-16 is selected as the divider unit for the proposed micro-architecture. The pseudo-code for a 32-bit radix-16 unsigned divider is described in Algorithm 1. The block diagram of the hardware architecture for the
divider is shown in Figure 4. In the hardware circuit, divisor is first multiplied with constants and the results are stored in registers. To compute these multiplications with constants, a lot of multipliers are required which are highly expensive in terms of area, delay and power. So, while implementing the hardware circuits, these multiplications are implemented using shifters and adders. Multiple of 2, 4 and 8 are calculated by left shifting the divisor, and the other multiples are determined by adding the results among them. The critical path of the circuit is found to be 3.10 ns at 40 nm technology node. In the division process, the next step is to update the quotient and remainder. At every clock cycle, the most significant 36-bits of the dividend is compared with the pre-calculated multiples of dividend. At first, the most significant bits of dividend is compared with 15*divisor. If the result says most significant bits of dividend is greater or equal to 15*divisor, then the quotient is left-shifted by 4-bits with a value “1111", 15*divisor is subtracted from the higher 36-bits of dividend and remainder is updated with the subtraction result. If the comparison result indicates that it is lesser than 15*divisor, then the comparison continues for lower multiples of divisor.

This process continues for eight clock cycles and at the end of 8th cycle, we get the desired quotient and remainder values. The divider unit discussed above takes eight clock cycles
to complete one division and is an unsigned divider. But, the ISA requires both signed and unsigned division. To enable signed operations, the magnitudes of the inputs are first determined. These 32-bit magnitudes are then fed to the divider circuit and magnitude of result is obtained. This result is finally converted to 2’s complement depending on the type of inputs (signed/unsigned) and the type of instruction. Whenever the result produces a signed negative number, the result of an unsigned divider circuit should be converted to a 32-bit signed negative number using 2’s complement representation. Otherwise, it should not be changed. Because of these signedunsigned conversions, two additional clock cycles are required, one prior to division, to determine the magnitude of the inputs and one after division to convert back the result to signed number.

![image-20230723102639082](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230723102639082.png)

From Table I, it can be seen that the delay of Baugh Wooley
signed multiplier circuit is 5.97 ns. If this circuit is used directly in the IE stage, the critical path of the overall system increases. Therefore, the hardware circuit of multiplier is modified into two stages. In the first stage, partial products are calculated using (1). Then, they are divided into six parts as shown in Figure 3 and are added. The adder results are then buffered to the next stage. In the second stage, the six buffered results are added again to get the final result. The critical path of the first stage consists of 1 HA (Half Adder) and 29 FAs (Full Adders). Whereas for the second stage, it consists of 1 HA and 47 FAs. The whole partial product segmentation is done in such a way that the delay of the first stage remains lesser than the second stage. This is because the input data of multiplier may come from register bank or from other stages of the pipeline. So, a multiplexer delay is expected at the inputs of multiplier circuit.

<img src="C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725083039758.png" alt="image-20230725083039758" style="zoom: 80%;" />

Similar to the implementation of multiplication, the hardware circuits for available division algorithms [21] are implemented using Verilog HDL and synthesized at UMC 40 nm technology node. Table II shows the area, power, delay, latency and throughput of these circuits. The throughput is measured in terms of the number of inputs the circuit can execute per clock cycle. From Table II, it can be seen that as we move to higher radix algorithms, latency of the circuit decreases and as a result, throughput increases. If the results of radix-16 and radix-32 are compared, it can be seen that there is not much improvement in latency and throughput. But, there is a significant increment in power and area. So, radix-16 is selected as the divider unit for the proposed micro-architecture. The pseudo-code for a 32-bit radix-16 unsigned divider is described in Algorithm 1. 

<img src="C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725083146188.png" alt="image-20230725083146188" style="zoom:67%;" />

The block diagram of the hardware architecture for the divider is shown in Figure 4. In the hardware circuit, divisor is first multiplied with constants and the results are stored in registers. To compute these multiplications with constants, a lot of multipliers are required which are highly expensive in terms of area, delay and power. So, while implementing the hardware circuits, these multiplications are implemented using shifters and adders. Multiple of 2, 4 and 8 are calculated by left shifting the divisor, and the other multiples are determined by adding the results among them. The critical path of the circuit is found to be 3.10 ns at 40 nm technology node. In the division process, the next step is to update the quotient and remainder. At every clock cycle, the most significant 36-bits of the dividend is compared with the pre-calculated multiples of dividend. At first, the most significant bits of dividend is compared with 15*divisor. If the result says most significant bits of dividend is greater or equal to 15*divisor, then the quotient is left-shifted by 4-bits with a value “1111", 15*divisor is subtracted from the higher 36-bits of dividend and remainder is updated with the subtraction result. If the comparison result indicates that it is lesser than 15*divisor, then the comparison continues for lower multiples of divisor.

This process continues for eight clock cycles and at the end of 8th cycle, we get the desired quotient and remainder values. The divider unit discussed above takes eight clock cycles
to complete one division and is an unsigned divider. But, the ISA requires both signed and unsigned division. To enable signed operations, the magnitudes of the inputs are first determined. These 32-bit magnitudes are then fed to the divider circuit and magnitude of result is obtained. This result is finally converted to 2’s complement depending on the type of inputs (signed/unsigned) and the type of instruction. Whenever the result produces a signed negative number, the result of an unsigned divider circuit should be converted to a 32-bit signed negative number using 2’s complement representation. Otherwise, it should not be changed. Because of these signedunsigned conversions, two additional clock cycles are required, one prior to division, to determine the magnitude of the inputs and one after division to convert back the result to signed number.

#### [8] F. Zaruba, F. Schuiki, L. Benini, Manticore: A 4096-Core RISC-V Chiplet Architecture for Ultraefficient Floating-Point Computing, Ieee Micro, 41 (2021) 36-42.



#### [9] B. Zimmer, Y. Lee, A. Puggelli, J. Kwak, R. Jevtic, B. Keller, S. Bailey, M. Blagojevic, P.F. Chiu, H.P. Le, P.H. Chen, N. Sutardja, R. Avizienis, A. Waterman, B. Richards, P. Flatresse, E. Alon, K. Asanovic, B. Nikolic, A RISC-V Vector Processor With Simultaneous-Switching Switched-Capacitor DC-DC Converters in 28 nm FDSOI, Ieee Journal of Solid-State Circuits, 51 (2016) 930-942.



#### [10] L.J. Zhu, L. Bamberg, A. Agnesina, F. Catthoor, D. Milojevic, M. Komalan, J. Ryckaert, A. Garcia-Ortiz, S.K. Lim, Heterogeneous 3D Integration for a RISC-V System With STT-MRAM, Ieee Computer Architecture Letters, 19 (2020) 51-54.

#### [11] I.G. del Rio, A.M. Hellin, O.R. Polo, M.J. Arribas, P. Parra, A. da Silva, J. Sanchez, S. Sanchez, A RISC-V Processor Design for Transparent Tracing, Electronics, 9 (2020).

#### [12] S. Tiwari, N. Gala, C. Rebeiro, V. Kamakoti, PERI: A Configurable Posit Enabled RISC-V Core, Acm Transactions on Architecture and Code Optimization, 18 (2021).

3 LEVERAGING RISC-V “F” EXTENSION FOR POSIT
This section describes how the RISC-V ISA can be leveraged and modified to include posit-based arithmetic operations.We leverage the “F” extension ofthe ISA with minimal modifications to support posit-based arithmetic. Before proceeding further, the reader is recommended to be cognizant with the “F” extension of the RISC-V ISA [47]. A gist of instructions comprising the “F” extension are captured in Table 1. This extension was designed to fit the IEEE-754 requirements. To support posit, some of these features were re-used, while others were modified or were not required. This section provides more details. We maintain the same register-file state for posit as that of the “F” extension, i.e., 32 posit registers: p0-p31 each 32-bits wide. The posit variant(pcsr) of the existing floating-point control and status register(fcsr) is shown in Figure 1. We now discuss the modifications in the pcsr for posits larly, there is no requirement of flags for invalid (NV), inexact (NX), overflow (OF), and underflow (UF). The posit exception of NaR is silent and thus does not get captured in the flags. The exception of divide-by-zero (DZ) is mapped to the DZ field of fflags.The pcsr register also holds a 5-bit es-mode field, which indicates the current value of es being used by the posit FPU and is required to deduce the posit number. To maintain compatibility with the “F” extension, the ps value is set to 32, and we expect all practical implementations of a posit FPU to support es values that can be represented within the 5-bit field. While the majority of implementations would support only a single value of es (thus causing this field to be read-only), later parts of this article propose a posit FPU design that can support up to two different es values, thereby using the es-mode field to perform the switching. This field can be modified using the standard CSR instructions of RISC-V. Implementations that support multiple es-mode values should rely on the software to perform a probe-and-find mechanism to identify all legal es values supported by the platform. Regarding IEEE-754, the RISC-V specification mandates that any floating-point operation resulting in a NaN should output a canonical NaN (i.e., 0x7fc00000). However, in posit,NaR hasa single representation that maps to the most negative 2’s complement signed integer. The fact that there is no notion of“unorderedness” in posits, allows a user to leverage integer-based comparison techniques to compare posit numbers. Unlike IEEE-754, in which two NaNs are not equal even after a similar pattern, two NaRs in posit are always equal. All instructions proposed in the “F” extension behave the sameway for posits as they do for IEEE754. The encoding of all instructions remains the same. The rm field in all instructions, except the posit-to-integer conversion ops, is ignored, since posit only supports a single rounding mode. For the posit-to-integer conversion ops, we realized that by supporting the round-to-zero (RTZ) mode, certain applications, like JPEG compression, can provide much better results compared to using the default round-to-nearest mode. Thus, we propose to keep the rm field in these instructions to mean the same as they do in the default specification. In the posit-based computation, the different exceptional scenarios, including subnormals, various types ofNaNs, zeros, and infinity, do not arise. Thus, the posit FPU needs to classify its input operand into four: zero, NaR, negative, or positive. Hence, the lower four bits are set in the output, and the remaining bits are set to zero.

## 结构_电路 摘录

#### [1] S. Jang, s.w. park, G. Kwon, S. Taeweon, Design and Evaluation of 32-Bit RISC-V Processor Using FPGA, KIPS Transactions on Computer and Communication Systems, 11 (2022) 1-8.

#### [2] Y. Kim, J.H. Lee, 조상운, A Design and Implementation of 32-bit Five-Stage RISC-V Processor Using FPGA, Journal of the Semiconductor & Display Technology, 21 (2022) 27-32.

#### [3] D. Zoni, A. Galimberti, Cost-effective fixed-point hardware support for RISC-V embedded systems, Journal of Systems Architecture, 126 (2022).

#### [4] H. Miyazaki, T. Kanamori, M.A. Islam, K. Kise, RVCoreP: An Optimized RISC-V Soft Processor of Five-Stage Pipelining, Ieice Transactions on Information and Systems, E103D (2020) 2494-2503.

##### 【五级流水线优化】

Design and Implementation of RVCoreP
In this section, we propose an optimized RV32I soft processor named RVCoreP (RISC-V core pipelined version). Firstly, we describe three optimization methods. Then, we describe the design and implementation of our proposal.
4.1 ALU Optimization
The data path to store the executed result in ALU using two data forwarding values to the ExMa pipeline register is the critical path in the baseline design. To mitigate the delay of this critical path, we discuss the ALU optimization scheme. According to the related work [16], the circuit speed
is improved by using exclusive OR instead of multiplexer to select the operation result for the ALU optimization on FPGA. Therefore, in this design of RVCoreP, exclusive OR is used to select the 32-bit executed result of ALU. As mentioned in the related work [17], one-hot encoding is used instead of the usual binary encoding for the control signal generation to select the ALU calculation result. As only one bit of the bit vector is 1 and the other bits are 0, and the control decisions are determined by the corresponding flip-flop bit in parallel. Therefore, the proposal adopts a one-hot encoding for ALU. The code 1 is the simplified description of a typical
ALU in the baseline where some operations of RV32I are excluded. The register named r rslt is the executed result of ALU. This value is selected by the 3-bit signal named sel, which is described in a case statement from line 7 to line 16. Since this description is mapped to hardware as a multiplexer that selects one from eight values, this circuit takes a certain time through several LUTs. The code 2 is the simplified description of the optimized ALU equivalent to the previous description in the code 1. The executed result of ALU named rslt is selected from eight values including 0 using exclusive OR on line 12. Each selected value is determined in advance using small multiplexers by a one-hot encoded selection signal named sel of 8-bit. Since this scheme can select a value without using a large multiplexer, this circuit is faster than the typical one. The preliminary evaluation of the operating frequency of the ALU alone targetting Xilinx Artix-7 FPGA showed that the frequency of the typical ALU was 230MHz while the frequency of the optimized ALU was 240MHz. This optimization is expected to improve the operating frequency of ALU by about 10MHz.

<img src="C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725091353974.png" alt="image-20230725091353974" style="zoom:67%;" />

4.2 Alignment and Sign-Extension Optimization
After applying the ALU optimization and the instruction fetch unit optimization described later, the critical path contains the data memory access, the alignment, and the signextension. The combinational circuit of the alignment and the sign-extension is named align/extend on the Ma stage in Fig. 1. RV32I has five load instructions which are load byte
(LB) to load 8-bit signed data, load byte unsigned (LBU) to load 8-bit unsigned data, load halfword (LH) to load 16bit signed data, load halfword unsigned (LHU) to load 16bit unsigned data, and load word (LW) to load 32-bit data. Therefore, align/extend unit has to align the loaded data by shifting 8, 16, or 24 bits right depends on the memory address and operation code of the load instructions. Then,sign-extension or zero extension is needed for load byte and load halfword instructions. Finally, the unit selects a proper value using a large multiplexer depends on the operation code of the instruction. We optimized the alignment and sign-extension using
the similar approach to the ALU optimization which is onehot encoding and using exclusive OR for value selection.
4.3 Instruction Fetch Unit Optimization

![image-20230725091651401](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725091651401.png)

We propose the two-stage pipelining of the branch predictor to improve the operating frequency of the instruction fetch unit, which contains the critical path on the baseline processor.
The related works [18], [19] have shown that the
pipelining of the branch predictor can improve the operating frequency of the soft processor when a complex branch predictor is used. The similar approach is applied to the proposed branch prediction including gshare and BTB. Figure 2 (a) shows a block diagram of a general branch
predictor and BTB in the baseline where the prediction is made in a single cycle. In gshare branch predictor, the index to access the PHT named m PHT is obtained by exclusive OR of PC and BHR named r BHR. If the fetched instruction is predicted as a conditional branch instruction using the BTB, it updates the BHR speculatively using the branch prediction in the If stage. The combinational circuit named join shifts BHR left
by 1-bit, and connects the branch prediction result to the least significant bit of the BHR. If the branch prediction missed, the BHR is updated with the correct branch history. The combinational circuit named comb that receives the value read from the BTB and the value read from the PHT generates the branch prediction named w btkn. The critical path of a general branch prediction mechanism is the red data path in Fig. 2 (a) which includes the access of the BTB, three LUTs, a multiplexer, wiring delays,and clock skew. In our preliminary evaluation, the access of the BTB composed of block RAM on a Xilinx Artix-7 FPGA takes about 2.54ns on the red path. Since the access of one LUT takes about 0.12ns, the access to the three LUTs necessary on the red path takes about 0.36ns. Also, the access to a multiplexer implemented using hard macro takes about 0.24ns, and other wiring delays and clock skew takes about 3ns. Therefore, the total delay of the path exceeds 6.1ns (165MHz) by adding the above delays. To improve the operating frequency for the proposed
processor, we split this critical path by two registers. Figure 2 (b) shows the block diagram of the pipelined
gshare and pipelined BTB for RVCoreP. The red critical path in Fig. 2 (a) is divided into three paths by two inserted registers named r btb and r pcx. The data acquired from the BTB is stored in the register r btb, and the register r pcx is inserted before exclusive OR to generate the index of PHT. It takes two cycles to determine the value of the next
PC in the instruction fetch stage. In the first cycle in the preIf stage, accessing the BTB and exclusive OR processing to determine the PHT index are performed. In the second cycle in the If stage, the value of the next PC is determined by using the results from the preIf stage and the instruction is fetched from the instruction memory. 

<img src="C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725091754527.png" alt="image-20230725091754527" style="zoom: 67%;" />

Figure 3 shows the pipeline diagram of instruction
fetching using the pipelined branch prediction in RVCoreP. The rectangles written as preIf represents the processing of the preIf stage, and the rectangles written as If represents the processing of the If stage. Assuming that four instructions are fetched in the order of Inst A, Inst B, Inst M, and Inst N. Inst A and Inst N are add and sub instructions, and these instruction addresses are 0x100 and 0x134, respectively. Inst B and Inst M are beq (branch if equal) and bne (branch if not equal) instruction, and these instruction addresses are 0x104 and 0x130, respectively. The next PC of Inst B is 0x130 when the branch is taken. In the clock cycle 1 when the value of PC is 0x100, the
If stage for Inst A and the preIf stage for the next instruction are executed. In the preIf stage, the value of BTB and PHT index used in the If stage for the next instruction 0x104 are prepared by using the current PC value of 0x100. In the clock cycle 2 when the value of PC is 0x104, the If stage for Inst B and the preIf stage for the next instruction are executed. In the If stage for Inst B, the next PC value is determined by using the value prepared in the preIf stage one cycle before. In the preIf stage, the value of BTB and PHT index used in the If stage for the next instruction 0x108 are prepared by using the current PC value of 0x104. Since Inst B is a conditional branch and assuming that it is predicted as taken, the next PC value is 0x130. In the clock cycle 3 when the value of PC is 0x130, the
If stage for Inst M and the preIf stage for the next instruction are executed. In the If stage for Inst M, the next PC value is determined as well but branch prediction is invalid, because the value prepared in the preIf stage one cycle before is for the instruction whose address is 0x108, and this value cannot be used in the If stage for Inst M whose address is 0x130. Therefore, if the value obtained by adding 4 to the previous PC does not match the current PC value, the branch prediction is invalid. From the above, the PC value used for BTB access is
the one cycle earlier value of PC, and the PC value used for PHT access is the value one cycle before the branch prediction is output. As a result, gshare outputs a prediction in 2 cycles. The BTB entry is updated using a value obtained by subtracting 4 from the PC value of the branch instruction. When updating a PHT entry, we have to keep the PHT index value used for the prediction and to update the PHT entry using this index when the actual branch outcome will be available. The prediction accuracy might drop slightly due to the
adverse effect of this optimization to make a prediction and update the index with the one cycle earlier value of PC.
4.4 RVCoreP Soft Processor

![image-20230725091852232](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725091852232.png)

 Figure 4 shows the block diagram of RVCoreP which is a five-stage pipelined processor including an instruction memory, a data memory, pipelined gshare and pipelined BTB. The ALU optimization, the alignment and signextension optimization, and the instruction fetch unit optimization are applied to the proposal. The unit named ALU opt in Fig. 4 is the optimized ALU. The detection timing of the load-use dependency between a load instruction and the following instruction using the loaded data is changed from the Id state on the baseline in Fig. 1 to the If stage using the combinational circuit named Load-use. To support the detection, a part of instruction decoder named decoder if is implemented in the If stage. decoder if decodes two source registers and one destination register for one instruction, and generates the write signals for the register file and data memory. This partial decoding of instruction in If stage allows us to detect the data dependency including load-use dependency in advance. Figure 5 shows the pipeline diagrams of the proposed processor. Figure 5 (a) shows the case where the pipeline is flushed due to a branch prediction miss. In the branch prediction mechanism, the branch target address from the BTB is used when the BTB is hit and the branch is predicted to be taken. The correct branch destination address calculation and check whether the branch prediction is correct or not is executed in the Ex stage and stored in the ExMa pipeline register. If the branch instruction is at the Ma stage and the branch prediction missed, the instructions in the If stage, Id stage, and Ex stage are flushed, which incurs a 3-cycle penalty.

![image-20230725091930504](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725091930504.png)

Figure 5 (b) shows the case where the pipeline stalls
due to the load-use dependency. In that case, the dependency is avoided by stalling the instruction following the load instruction. Using the decoder if to partially decode the instruction in the If stage helps to detect the dependency by load instruction in Id stage and an instruction in the If stage, and the detection result is stored in the IdEx pipeline register. If the load instruction is in the Ex stage and there is a data dependency on load instruction, this processor inserts a bubble in IdEx pipeline register, and stall instructions in the If stage and Id stage, which incurs a one-cycle penalty.

#### [5] Z.Y. Li, Y.H. Huang, L.F. Tian, R.M. Zhu, S.L. Xiao, Z.Y. Yu, A Low-Power Asynchronous RISC-V Processor With Propagated Timing Constraints Method, Ieee Transactions on Circuits and Systems Ii-Express Briefs, 68 (2021) 3153-3157.

#### [6] A. Coluccio, A. Ieva, F. Riente, M.R. Roch, M. Ottavi, M. Vacca, RISC-Vlim, a RISC-V Framework for Logic-in-Memory Architectures, Electronics, 11 (2022).

##### 【用一个能够存储数据和执行内存计算的电路来代替数据存储器】

Architecture

 The case study focuses on the core RI5CY or CV32E40P, a specific RISC-V implementation, developed and maintained by the PULP platform (https://www.pulp-platform.org/, last accessed on 15 September 2022). As already stated, the RIC5Y core was chosen because of its flexibility that is characteristic of the RISC-V standard family. As in all RISC-V implementations, it is possible to extend the ISA to enable the core to support new customized functionalities. Therefore, the RI5CY core is a good candidate for integration of the LiM concept. RI5CY is a four-stage, in-order 32-bit core [20]. Figure 1 presents an overview of the RI5CY architecture.

![image-20230725094213327](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725094213327.png)

The given memory model is replaced with a LiM model. Additional logic within the RI5CY core is added to support new LiM management instructions. Figure 2 represents, in green, the significant blocks that are changed with respect to the initial architecture. The framework relies on the existing interface between the processor and the memory. The RI5CY core introduces new instructions to control the new LiM, so the decoder within the instruction fetch stage (IF) is enlarged. At the same time, a new immediate type is required due to the different format of the instructions. Consequently, the sign-extension block is also changed. More details on the interface and the new instructions are presented in the next section, following a full description of the proposed LiM architecture.

![image-20230725094249076](C:\Users\张云鑫\AppData\Roaming\Typora\typora-user-images\image-20230725094249076.png)

#### [7] C.A.A. Rodrigues, Heterogeneous Fault Tolerance Architecture Based on Arm and RISC-V Processors, 2019.

## 系统工作电压 摘录

#### [1] B. Zimmer, P.F. Chiu, B. Nikolic, K. Asanovic, Reprogrammable Redundancy for SRAM-Based Cache V-min Reduction in a 28-nm RISC-V Processor, Ieee Journal of Solid-State Circuits, 52 (2017) 2589-2600.

## 性能优化 摘录

#### [1] E. Tabanelli, G. Tagliavini, L. Benini, Optimizing Random Forest-Based Inference on RISC-V MCUs at the Extreme Edge, Ieee Transactions on Computer-Aided Design of Integrated Circuits and Systems, 41 (2022) 4516-4526.

## 简单读一下

#### [1] H. Legenvre, P. Kauttu, M. Bos, R. Khawand, Is Open Hardware Worthwhile? Learning from Thales' Experience with RISC-V, Research-Technology Management, 63 (2020) 44-53.

#### [2] S. Di Mascio, A. Menicucci, E. Gill, G. Furano, C. Monteleone, Leveraging the Openness and Modularity of RISC-V in Space, Journal of Aerospace Information Systems, 16 (2019) 454-472.

#### [3] F. Szkandera, Build Your Own RISC-V CPU > Even home-brew processors can use hot new tech, Ieee Spectrum, 58 (2021) 16-18.

#### [4] S.K. Moore, RISC-V Dives Into AI > Demand for machine learning means RISC-V chips will be everywhere, Ieee Spectrum, 59 (2022) 5-7.

#### [5] L. Laursen, RISC-V Guns for Raspberry Pi > Legacy chips could be unseated as open chip architecture gains adoption beyond the Internet of Things, Ieee Spectrum, 59 (2022) 12-12.

#### [6] S. Greengard, Will RISC-V Revolutionize Computing?, Communications of the Acm, 63 (2020) 30-32.